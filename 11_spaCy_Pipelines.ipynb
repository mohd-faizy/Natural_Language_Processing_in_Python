{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>spaCy Pipelines</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Natural Language Processing with spaCy)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "1. [spaCy Pipeline Basics](#section-1)\n",
        "2. [Pipeline Structure and Components](#section-2)\n",
        "3. [Adding Pipes and Optimization](#section-3)\n",
        "4. [Analyzing Pipeline Components](#section-4)\n",
        "5. [The spaCy EntityRuler](#section-5)\n",
        "6. [Adding EntityRuler to the Pipeline](#section-6)\n",
        "7. [EntityRuler in Action: Integration Strategies](#section-7)\n",
        "8. [Regular Expressions (RegEx) with spaCy](#section-8)\n",
        "9. [RegEx Implementation in spaCy](#section-9)\n",
        "10. [The spaCy Matcher](#section-10)\n",
        "11. [The spaCy PhraseMatcher](#section-11)\n",
        "12. [Conclusion](#section-12)\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. spaCy Pipeline Basics</span><br>\n",
        "\n",
        "spaCy is a powerful library for Natural Language Processing (NLP). At its core, spaCy operates using a processing pipeline.\n",
        "\n",
        "### How it works\n",
        "1.  **Tokenization**: spaCy first tokenizes the text to produce a `Doc` object.\n",
        "2.  **Processing**: The `Doc` is then processed in several different steps by the processing pipeline.\n",
        "\n",
        "To use spaCy, we typically load a pre-trained model (like `en_core_web_sm`) which contains the pipeline definitions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the spaCy library\n",
        "import spacy\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define example text\n",
        "example_text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "\n",
        "# Process the text to create a Doc object\n",
        "doc = nlp(example_text)\n",
        "\n",
        "# Verify the object type\n",
        "print(type(doc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. Pipeline Structure and Components</span><br>\n",
        "\n",
        "A **pipeline** is a sequence of pipes, or \"actors,\" that perform operations on the data.\n",
        "\n",
        "### The NER Pipeline\n",
        "A typical spaCy Named Entity Recognition (NER) pipeline involves the following steps:\n",
        "1.  **Tokenization**: Splitting text into words/punctuation.\n",
        "2.  **Named entity identification**: Locating the entities.\n",
        "3.  **Named entity classification**: Assigning labels (e.g., ORG, GPE) to entities.\n",
        "\n",
        "The flow looks like this:\n",
        "`Input text` -> `Tokenizer` -> `EntityRuler` -> `EntityLinker` -> `Doc with annotated entities`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process text\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "# Accessing named entities processed by the pipeline\n",
        "# We use list comprehension to extract text from doc.ents\n",
        "print([ent.text for ent in doc.ents])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. Adding Pipes and Optimization</span><br>\n",
        "\n",
        "We can customize pipelines by adding specific components. One such component is the `sentencizer`, which performs sentence segmentation.\n",
        "\n",
        "### Performance Comparison\n",
        "Below, we compare the processing time of a full pipeline versus a blank pipeline with only a `sentencizer`.\n",
        "\n",
        "#### 1. Using the Full Model (`en_core_web_sm`)\n",
        "This model includes tagger, parser, and NER, which takes more time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "import time\n",
        "\n",
        "# Create a large text dataset\n",
        "text = \" \".join([\"This is a test sentence.\"]*10000)\n",
        "\n",
        "# Load the full model\n",
        "en_core_sm_nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Process text\n",
        "doc = en_core_sm_nlp(text)\n",
        "\n",
        "# Calculate duration\n",
        "duration = (time.time() - start_time) / 60.0\n",
        "\n",
        "print(f\"Finished processing with en_core_web_sm model in {round(duration, 5)} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 2. Using a Blank Model with `sentencizer`\n",
        "If we only need sentence segmentation, we can create a blank model and add the `sentencizer` pipe. This is significantly faster.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "import time\n",
        "\n",
        "# Create a large text dataset\n",
        "text = \" \".join([\"This is a test sentence.\"]*10000)\n",
        "\n",
        "# Create a blank English model\n",
        "blank_nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Add the sentencizer pipe\n",
        "blank_nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Process text\n",
        "doc = blank_nlp(text)\n",
        "\n",
        "# Calculate duration\n",
        "duration = (time.time() - start_time) / 60.0\n",
        "\n",
        "print(f\"Finished processing with blank model in {round(duration, 5)} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Using a blank model with specific pipes is highly efficient when you do not need the full capabilities (like dependency parsing or NER) of the pre-trained models. </div>\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Analyzing Pipeline Components</span><br>\n",
        "\n",
        "To understand what is happening inside a pipeline, spaCy provides the `nlp.analyze_pipes()` method.\n",
        "\n",
        "This method determines:\n",
        "*   Attributes that pipeline components set.\n",
        "*   Scores a component produces during training.\n",
        "*   Presence of all required attributes.\n",
        "\n",
        "Setting `pretty=True` prints a readable table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Analyze the pipeline and print the results\n",
        "analysis = nlp.analyze_pipes(pretty=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Pipeline Overview Table\n",
        "The output of the analysis typically looks like this:\n",
        "\n",
        "| # | Component | Assigns | Requires | Scores | Retokenizes |\n",
        "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
        "| 0 | tok2vec | doc.tensor | | | False |\n",
        "| 1 | tagger | token.tag | | tag_acc | False |\n",
        "| 2 | parser | token.dep, token.head, token.is_sent_start, doc.sents | | dep_uas, dep_las, sents_p, sents_r, sents_f | False |\n",
        "| 3 | attribute_ruler | | | | False |\n",
        "| 4 | lemmatizer | token.lemma | | lemma_acc | False |\n",
        "| 5 | ner | doc.ents, token.ent_iob, token.ent_type | | ents_f, ents_p, ents_r | False |\n",
        "| 6 | entity_linker | token.ent_kb_id | doc.ents, doc.sents, token.ent_iob, token.ent_type | nel_micro_f, nel_micro_r, nel_micro_p | False |\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. The spaCy EntityRuler</span><br>\n",
        "\n",
        "The `EntityRuler` is a component that adds named entities to a `Doc` container based on pattern matching. It can be used on its own or combined with the statistical `EntityRecognizer`.\n",
        "\n",
        "### Types of Patterns\n",
        "\n",
        "1.  **Phrase entity patterns**: For exact string matches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    {\"label\": \"ORG\", \"pattern\": \"Microsoft\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "2.  **Token entity patterns**: A list of dictionaries, where each dictionary describes one token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. Adding EntityRuler to the Pipeline</span><br>\n",
        "\n",
        "To use the EntityRuler, we add it to the pipeline using `.add_pipe()` and then add patterns using `.add_patterns()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Create a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Add the EntityRuler pipe\n",
        "entity_ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "# Define patterns\n",
        "patterns = [\n",
        "    {\"label\": \"ORG\", \"pattern\": \"Microsoft\"},\n",
        "    {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}\n",
        "]\n",
        "\n",
        "# Add patterns to the ruler\n",
        "entity_ruler.add_patterns(patterns)\n",
        "\n",
        "# Process text\n",
        "doc = nlp(\"Microsoft is hiring software developer in San Francisco.\")\n",
        "\n",
        "# Print entities found\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Expected Output:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "[('Microsoft', 'ORG'), ('San Francisco', 'GPE')]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. EntityRuler in Action: Integration Strategies</span><br>\n",
        "\n",
        "The `EntityRuler` integrates with other spaCy components. A key consideration is **where** in the pipeline you place the ruler.\n",
        "\n",
        "### 1. Default Model Behavior (No EntityRuler)\n",
        "Without the ruler, the statistical model might misclassify entities based on context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Manhattan associates is a company in the U.S.\")\n",
        "\n",
        "# The model might mistake 'Manhattan' for a GPE (Location) instead of part of an ORG\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "# Output: [('Manhattan', 'GPE'), ('U.S.', 'GPE')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. EntityRuler AFTER existing NER\n",
        "If added `after='ner'`, the ruler will only find entities that the NER model missed or didn't overwrite.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add ruler after NER\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", after='ner')\n",
        "\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": [{\"lower\": \"manhattan\"}, {\"lower\": \"associates\"}]}]\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "doc = nlp(\"Manhattan associates is a company in the U.S.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "# Output might still be GPE because NER ran first and labeled 'Manhattan'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. EntityRuler BEFORE existing NER\n",
        "If added `before='ner'`, the ruler's matches take precedence. The NER model will respect the existing entities found by the ruler.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add ruler BEFORE NER\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
        "\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": [{\"lower\": \"manhattan\"}, {\"lower\": \"associates\"}]}]\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "doc = nlp(\"Manhattan associates is a company in the U.S.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "# Output: [('Manhattan associates', 'ORG'), ('U.S.', 'GPE')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 8. Regular Expressions (RegEx) with spaCy</span><br>\n",
        "\n",
        "Regular Expressions (RegEx) are used for complex string matching patterns. They are useful for rule-based information extraction.\n",
        "\n",
        "### Strengths and Weaknesses\n",
        "\n",
        "| Pros | Cons |\n",
        "| :--- | :--- |\n",
        "| Enables writing robust rules to retrieve information | Syntax is challenging for beginners |\n",
        "| Can find many types of variance in strings | Requires knowledge of all ways a pattern may be mentioned |\n",
        "| Runs fast | |\n",
        "| Supported by most programming languages | |\n",
        "\n",
        "### RegEx in Standard Python\n",
        "Python uses the `re` library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Define a pattern for phone numbers (XXX-XXX-XXXX)\n",
        "pattern = r\"((\\d){3}-(\\d){3}-(\\d){4})\"\n",
        "text = \"Our phone number is 832-123-5555 and their phone number is 425-123-4567.\"\n",
        "\n",
        "# Find matches\n",
        "iter_matches = re.finditer(pattern, text)\n",
        "\n",
        "for match in iter_matches:\n",
        "    start_char = match.start()\n",
        "    end_char = match.end()\n",
        "    print(\"Start character:\", start_char, \"| End character:\", end_char, \n",
        "          \"| Matching text:\", text[start_char:end_char])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 9. RegEx Implementation in spaCy</span><br>\n",
        "\n",
        "spaCy allows RegEx-like capabilities within its pipeline components: `Matcher`, `PhraseMatcher`, and `EntityRuler`. We can use token attributes like `SHAPE` to mimic RegEx behavior.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "text = \"Our phone number is 832-123-5555 and their phone number is 425-123-4567.\"\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Define patterns using token attributes\n",
        "# \"ddd\" represents 3 digits, \"dddd\" represents 4 digits\n",
        "patterns = [{\n",
        "    \"label\": \"PHONE_NUMBER\",\n",
        "    \"pattern\": [\n",
        "        {\"SHAPE\": \"ddd\"},\n",
        "        {\"ORTH\": \"-\"},\n",
        "        {\"SHAPE\": \"ddd\"},\n",
        "        {\"ORTH\": \"-\"},\n",
        "        {\"SHAPE\": \"dddd\"}\n",
        "    ]\n",
        "}]\n",
        "\n",
        "# Add EntityRuler\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "# Process text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print results\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 10. The spaCy Matcher</span><br>\n",
        "\n",
        "The `Matcher` class provides a readable, production-level alternative to complex RegEx strings. It matches sequences of tokens based on pattern dictionaries.\n",
        "\n",
        "### Basic Matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Good morning, this is our first day on campus.\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Pattern: Case-insensitive match for \"good\" followed by \"morning\"\n",
        "pattern = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}]\n",
        "matcher.add(\"morning_greeting\", [pattern])\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Start token:\", start, \"| End token:\", end, \"| Matched text:\", doc[start:end].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Extended Syntax Support\n",
        "The Matcher supports operators similar to Python's `in`, `not in`, and comparison operators.\n",
        "\n",
        "| Attribute | Value Type | Description |\n",
        "| :--- | :--- | :--- |\n",
        "| `IN` | any type | Attribute value is a member of a list |\n",
        "| `NOT_IN` | any type | Attribute value is *not* a member of a list |\n",
        "| `==`, `>=`, `<=`, `>`, `<` | int, float | Comparison operators for equality or inequality checks |\n",
        "\n",
        "#### Example: Using the `IN` Operator\n",
        "Matching both \"Good morning\" and \"Good evening\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = nlp(\"Good morning and good evening.\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Pattern using IN operator\n",
        "pattern = [{\"LOWER\": \"good\"}, {\"LOWER\": {\"IN\": [\"morning\", \"evening\"]}}]\n",
        "\n",
        "matcher.add(\"morning_greeting\", [pattern])\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Start token:\", start, \"| End token:\", end, \"| Matched text:\", doc[start:end].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 11. The spaCy PhraseMatcher</span><br>\n",
        "\n",
        "The `PhraseMatcher` is optimized for matching large lists of phrases in a text. It is generally more efficient than `Matcher` when dealing with exact string matches.\n",
        "\n",
        "### Basic Phrase Matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "\n",
        "# List of terms to match\n",
        "terms = [\"Bill Gates\", \"John Smith\"]\n",
        "\n",
        "# Convert terms to Doc objects\n",
        "patterns = [nlp.make_doc(term) for term in terms]\n",
        "\n",
        "# Add patterns\n",
        "matcher.add(\"PeopleOfInterest\", patterns)\n",
        "\n",
        "doc = nlp(\"Bill Gates met John Smith for an important discussion regarding importance of AI.\")\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Start token:\", start, \"| End token:\", end, \"| Matched text:\", doc[start:end].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Using the `attr` Argument\n",
        "We can configure the `PhraseMatcher` to match on specific token attributes, such as `LOWER` (case-insensitive) or `SHAPE`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Case-insensitive matching\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "terms = [\"Government\", \"Investment\"]\n",
        "patterns = [nlp.make_doc(term) for term in terms]\n",
        "matcher.add(\"InvestmentTerms\", patterns)\n",
        "\n",
        "doc = nlp(\"It was interesting to the investment division of the government.\")\n",
        "# This will match \"investment\" and \"government\" despite case differences\n",
        "\n",
        "# Example 2: Shape matching (IP Addresses)\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
        "terms = [\"110.0.0.0\", \"101.243.0.0\"]\n",
        "patterns = [nlp.make_doc(term) for term in terms]\n",
        "matcher.add(\"IPAddresses\", patterns)\n",
        "\n",
        "doc = nlp(\"The tracked IP address was 234.135.0.0.\")\n",
        "# This will match \"234.135.0.0\" because it has the same shape as the terms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 12. Conclusion</span><br>\n",
        "\n",
        "In this notebook, we explored the powerful capabilities of **spaCy pipelines**.\n",
        "\n",
        "**Key Takeaways:**\n",
        "1.  **Pipelines**: spaCy processes text through a sequence of pipes. We can analyze these using `nlp.analyze_pipes()`.\n",
        "2.  **Customization**: We can add custom components like `sentencizer` or `EntityRuler` to blank or existing models.\n",
        "3.  **EntityRuler**: This component allows for rule-based entity recognition. Its placement (`before` or `after` NER) is critical for determining which entities take precedence.\n",
        "4.  **Pattern Matching**:\n",
        "    *   **RegEx**: Useful but complex; spaCy supports RegEx-like logic via token attributes.\n",
        "    *   **Matcher**: A readable, token-based matching engine supporting extended syntax (`IN`, comparison).\n",
        "    *   **PhraseMatcher**: Highly efficient for matching large lists of exact phrases.\n",
        "\n",
        "**Next Steps:**\n",
        "*   Experiment with combining `EntityRuler` and statistical models to improve accuracy on domain-specific data.\n",
        "*   Utilize `PhraseMatcher` for large-scale keyword extraction tasks.\n",
        "*   Explore custom pipeline components to perform specialized text processing tasks.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}