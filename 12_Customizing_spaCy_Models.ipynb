{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>Customizing spaCy Models</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Natural Language Processing with spaCy)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Why Train spaCy Models?](#section-1)\n",
        "2. [Training Data Preparation](#section-2)\n",
        "3. [Training with spaCy](#section-3)\n",
        "4. [Course Wrap-up and Review](#section-4)\n",
        "5. [Conclusion](#conclusion)\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. Why Train spaCy Models?</span><br>\n",
        "\n",
        "### The Need for Customization\n",
        "\n",
        "Standard pre-trained spaCy models are excellent for general NLP use cases. However, they may not have encountered data from specific domains during their initial training. \n",
        "\n",
        "**Common Specific Domains:**\n",
        "*   **Twitter Data:** Contains slang, hashtags, and informal grammar.\n",
        "*   **Medical Data:** Contains complex pharmaceutical names, symptoms, and diagnosis codes (e.g., \"pulmonary fibrosis\", \"atrial fibrillation\").\n",
        "\n",
        "Training a custom model allows you to achieve better results on your specific domain and is essential for domain-specific text classification or Named Entity Recognition (NER).\n",
        "\n",
        "### Assessing Model Performance\n",
        "\n",
        "Before starting the training process, you should ask:\n",
        "1.  Do the default spaCy models perform well enough on our data?\n",
        "2.  Does our domain include many labels that are absent in spaCy models?\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Always test the pre-trained model first. If it fails to recognize core entities in your domain, customization is necessary. </div>\n",
        "\n",
        "### Example: Misclassification\n",
        "In the example below, the standard model might misclassify \"Oxford Street\". While it is a location, specific contexts might require specific labeling, or the model might mistake it for an Organization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Test text\n",
        "text = \"The car was navigating to the Oxford Street.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print entities and their labels\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Analysis:**\n",
        "If the output is `[('the Oxford Street', 'ORG')]` or similar, and you require it to be a `GPE` (Geopolitical Entity) or `FAC` (Facility), the model requires fine-tuning.\n",
        "\n",
        "### Output Labels in spaCy Models\n",
        "If your domain includes labels absent in standard models (e.g., specific financial terms like `CAGR`, medical terms like `DISEASE` or `CHEMICAL`), you must train a custom model.\n",
        "\n",
        "**Steps for Custom Model Training:**\n",
        "1.  **Collect** domain-specific data.\n",
        "2.  **Annotate** the data (label intents, entities, etc.).\n",
        "3.  **Determine** whether to update an existing model or train a model from scratch.\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. Training Data Preparation</span><br>\n",
        "\n",
        "### The Training Workflow\n",
        "Training a model involves an iterative process:\n",
        "1.  Annotate and prepare input data.\n",
        "2.  Initialize the model weights.\n",
        "3.  Predict a few examples with current weights.\n",
        "4.  Compare predictions with correct answers.\n",
        "5.  Use an optimizer to calculate weights that improve performance.\n",
        "6.  Update weights slightly.\n",
        "7.  Repeat from step 3.\n",
        "\n",
        "### Annotating Data\n",
        "Annotation is the process of labeling the intent or entities within your text. The raw data usually comes in a dictionary format or JSON-like structure before being converted for spaCy.\n",
        "\n",
        "**Example 1: Medical Data Annotation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annotated_data_medical = {\n",
        "    \"sentence\": \"An antiviral drugs used against influenza is neuraminidase inhibitors.\",\n",
        "    \"entities\": {\n",
        "        \"label\": \"Medicine\",\n",
        "        \"value\": \"neuraminidase inhibitors\",\n",
        "    }\n",
        "}\n",
        "print(annotated_data_medical)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Example 2: General Entity Annotation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annotated_data_general = {\n",
        "    \"sentence\": \"Bill Gates visited the SFO Airport.\",\n",
        "    \"entities\": [\n",
        "        {\"label\": \"PERSON\", \"value\": \"Bill Gates\"},\n",
        "        {\"label\": \"LOC\", \"value\": \"SFO Airport\"}\n",
        "    ]\n",
        "}\n",
        "print(annotated_data_general)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### spaCy Training Data Format\n",
        "To feed data into spaCy, it must be converted into a specific format: a list of tuples.\n",
        "*   **First element:** The raw sentence string.\n",
        "*   **Second element:** A dictionary containing an `\"entities\"` key.\n",
        "*   **Entities list:** A list of tuples `(start_char, end_char, label)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The required format for spaCy training\n",
        "training_data = [\n",
        "    (\"I will visit you in Austin.\", {\"entities\": [(20, 26, \"GPE\")]}),\n",
        "    (\"I'm going to Sam's house.\", {\"entities\": [(13, 18, \"PERSON\"), (19, 24, \"GPE\")]}),\n",
        "    (\"I will go.\", {\"entities\": []})\n",
        "]\n",
        "\n",
        "print(\"Training Data Sample:\", training_data[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### The `Example` Object\n",
        "We cannot feed raw text directly to the training loop. spaCy v3 introduces the `Example` object, which holds the predicted document (`doc`) and the reference annotations (`gold standard`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Raw text and annotations\n",
        "text = \"I will visit you in Austin.\"\n",
        "annotations = {\"entities\": [(20, 26, \"GPE\")]}\n",
        "\n",
        "# Create a Doc object\n",
        "doc = nlp.make_doc(text)\n",
        "\n",
        "# Create an Example object\n",
        "example_sentence = Example.from_dict(doc, annotations)\n",
        "\n",
        "# Inspect the example object (converted back to dict for visibility)\n",
        "print(example_sentence.to_dict())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. Training with spaCy</span><br>\n",
        "\n",
        "### Training Steps Implementation\n",
        "When updating an existing model, we generally follow these steps:\n",
        "1.  Annotate and prepare input data.\n",
        "2.  **Disable other pipeline components** (to prevent them from being affected by training).\n",
        "3.  Train the model for a few **epochs**.\n",
        "4.  Evaluate model performance.\n",
        "\n",
        "### Disabling Pipeline Components\n",
        "If we are only training the Named Entity Recognizer (NER), we should disable the tagger, parser, and other components to keep their weights stable and speed up training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify pipes to disable (everything except 'ner')\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "\n",
        "# Disable them using the context manager or explicitly\n",
        "# Note: In a real script, this is often done inside a 'with nlp.select_pipes(...):' block\n",
        "# or by using nlp.disable_pipes().\n",
        "print(f\"Pipes to disable: {other_pipes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### The Training Loop\n",
        "Here is the complete procedure to update the model. We iterate through the data multiple times (epochs), shuffle the data to prevent order bias, and update the model using `nlp.update`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import spacy\n",
        "from spacy.training import Example\n",
        "\n",
        "# Load model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define training data\n",
        "training_data = [\n",
        "    (\"I will visit you in Austin.\", {\"entities\": [(20, 26, \"GPE\")]}),\n",
        "    (\"I'm going to Sam's house.\", {\"entities\": [(13, 18, \"PERSON\"), (19, 24, \"GPE\")]}),\n",
        "    (\"I will go.\", {\"entities\": []})\n",
        "]\n",
        "\n",
        "# 1. Create an optimizer\n",
        "optimizer = nlp.create_optimizer()\n",
        "\n",
        "# 2. Define other pipes to disable\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "\n",
        "# 3. Training loop\n",
        "epochs = 5\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    for i in range(epochs):\n",
        "        random.shuffle(training_data)\n",
        "        losses = {}\n",
        "        \n",
        "        # Batch up the examples using spaCy's minibatch is recommended, \n",
        "        # but here we iterate individually for demonstration as per the slides.\n",
        "        for text, annotation in training_data:\n",
        "            doc = nlp.make_doc(text)\n",
        "            example = Example.from_dict(doc, annotation)\n",
        "            \n",
        "            # Update the model\n",
        "            nlp.update([example], sgd=optimizer, losses=losses)\n",
        "            \n",
        "        print(f\"Epoch {i+1} Losses: {losses}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Saving and Loading the Model\n",
        "Once trained, you must save the component to disk to use it later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define output directory\n",
        "output_dir = \"ner_model_output\"\n",
        "\n",
        "# Clean up previous runs for this notebook\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "# Save the NER component specifically (or nlp.to_disk for the whole pipeline)\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "ner.to_disk(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")\n",
        "\n",
        "# Loading the saved model component back\n",
        "# We create a blank NER pipe and load the data into it\n",
        "new_ner = nlp.create_pipe(\"ner\")\n",
        "new_ner.from_disk(output_dir)\n",
        "\n",
        "# In a real scenario, you would add this 'new_ner' to a fresh nlp object\n",
        "# nlp_new.add_pipe(new_ner, name=\"ner_custom\")\n",
        "print(\"Model loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Model for Inference\n",
        "After loading the model, you can use it to predict entities on new text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference example\n",
        "text = \"I am flying to Austin specifically.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract entities\n",
        "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "print(f\"Inference Results: {entities}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Course Wrap-up and Review</span><br>\n",
        "\n",
        "This section summarizes the key concepts covered in the \"Natural Language Processing with spaCy\" course.\n",
        "\n",
        "### Chapter 1: Introduction to NLP and spaCy\n",
        "*   Focused on using spaCy's text processing pipelines.\n",
        "*   Key components: Tokenizer, Tagger, Parser, NER.\n",
        "*   Output: The `Doc` object.\n",
        "\n",
        "### Chapter 2: Linguistic Annotations and Word Vectors\n",
        "*   Worked with spaCy classes: `Doc`, `Token`, and `Span`.\n",
        "*   Used word vectors to predict semantic similarities (e.g., King - Man + Woman = Queen).\n",
        "\n",
        "### Chapter 3: Data Analysis with spaCy\n",
        "*   Used `Matcher` and `PhraseMatcher` to extract terms based on patterns.\n",
        "\n",
        "**Matcher Example Code:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher, PhraseMatcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# 1. Token Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "# Pattern: \"good\" followed by \"morning\" or \"evening\"\n",
        "pattern = [{\"LOWER\": \"good\"}, {\"LOWER\": {\"IN\": [\"morning\", \"evening\"]}}]\n",
        "matcher.add(\"morning_greeting\", [pattern])\n",
        "\n",
        "# 2. Phrase Matcher\n",
        "phrase_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "terms = [\"InvestmentTerms\", \"Stocks\", \"Bonds\"]\n",
        "patterns = [nlp.make_doc(term) for term in terms]\n",
        "phrase_matcher.add(\"InvestmentTerms\", patterns)\n",
        "\n",
        "print(\"Matchers initialized successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Chapter 4: Customizing spaCy Models\n",
        "*   Annotating data for training.\n",
        "*   Training models (updating weights).\n",
        "*   Using custom models for inference.\n",
        "\n",
        "### Recommended Resources\n",
        "To further your learning, the following resources are recommended:\n",
        "*   Introduction to Deep Learning in Python\n",
        "*   Introduction to Deep Learning with PyTorch\n",
        "*   Introduction to ChatGPT\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. Conclusion</span><br>\n",
        "\n",
        "### Summary\n",
        "In this notebook, we explored the advanced capabilities of spaCy, specifically focusing on **custom model training**. We learned that while pre-trained models are powerful, specific domains like medicine or social media often require custom training data to achieve high accuracy.\n",
        "\n",
        "**Key Takeaways:**\n",
        "1.  **Data Preparation is Key:** The quality of your model depends heavily on the quality and format of your annotated data (List of tuples with character offsets).\n",
        "2.  **The `Example` Object:** spaCy v3 requires converting raw text and annotations into `Example` objects for training.\n",
        "3.  **Training Loop:** We must disable unrelated pipeline components, shuffle data, and iterate through epochs to update model weights using `nlp.update`.\n",
        "4.  **Persistence:** Trained models can be saved to disk and reloaded for inference in production environments.\n",
        "\n",
        "### Next Steps\n",
        "*   **Practice:** Create a custom dataset for a domain you are interested in (e.g., sports, finance).\n",
        "*   **Experiment:** Try training a model from scratch (blank language model) versus updating an existing one to see the difference in performance.\n",
        "*   **Explore:** Look into spaCy's config system (`config.cfg`) for more advanced hyperparameter tuning and training configurations.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}