{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>INTRODUCTION TO NLP FEATURE ENGINEERING</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(FEATURE ENGINEERING FOR NLP IN PYTHON)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Introduction to Numerical and Textual Data](#section-1)\n",
        "2. [One-Hot Encoding](#section-2)\n",
        "3. [Text Pre-processing and Vectorization](#section-3)\n",
        "4. [Basic Feature Concepts (POS & NER)](#section-4)\n",
        "5. [Implementing Basic Feature Extraction](#section-5)\n",
        "6. [Advanced Feature Extraction: Hashtags and Mentions](#section-6)\n",
        "7. [Readability Tests](#section-7)\n",
        "8. [Conclusion](#section-8)\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. INTRODUCTION TO NUMERICAL AND TEXTUAL DATA</span><br>\n",
        "\n",
        "### Numerical Data\n",
        "Machine learning models generally require numerical input. Standard datasets, like the famous Iris dataset, come in a format where features are already numerical.\n",
        "\n",
        "**Iris Dataset Example:**\n",
        "\n",
        "| sepal length | sepal width | petal length | petal width | class |\n",
        "| :--- | :--- | :--- | :--- | :--- |\n",
        "| 6.3 | 2.9 | 5.6 | 1.8 | Iris-virginica |\n",
        "| 4.9 | 3.0 | 1.4 | 0.2 | Iris-setosa |\n",
        "| 5.6 | 2.9 | 3.6 | 1.3 | Iris-versicolor |\n",
        "| 6.0 | 2.7 | 5.1 | 1.6 | Iris-versicolor |\n",
        "| 7.2 | 3.6 | 6.1 | 2.5 | Iris-virginica |\n",
        "\n",
        "### Textual Data\n",
        "However, Natural Language Processing (NLP) deals with unstructured text. Before we can feed this into a model, we must perform feature engineering to convert text into numbers.\n",
        "\n",
        "**Movie Review Dataset Example:**\n",
        "\n",
        "| review | class |\n",
        "| :--- | :--- |\n",
        "| This movie is for dog lovers. A very poignant... | positive |\n",
        "| The movie is forgettable. The plot lacked... | negative |\n",
        "| A truly amazing movie about dogs. A gripping... | positive |\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. ONE-HOT ENCODING</span><br>\n",
        "\n",
        "When dealing with categorical data (like gender, city, or product category), we cannot simply use the strings. One common technique to convert these categories into numbers is **One-hot encoding**.\n",
        "\n",
        "### Conceptual Transformation\n",
        "\n",
        "**Original Data:**\n",
        "| sex |\n",
        "| :--- |\n",
        "| female |\n",
        "| male |\n",
        "| female |\n",
        "| male |\n",
        "| female |\n",
        "\n",
        "**One-Hot Encoded Data:**\n",
        "| sex | sex_female | sex_male |\n",
        "| :--- | :--- | :--- |\n",
        "| female | 1 | 0 |\n",
        "| male | 0 | 1 |\n",
        "| female | 1 | 0 |\n",
        "| male | 0 | 1 |\n",
        "| female | 1 | 0 |\n",
        "\n",
        "### Implementation with Pandas\n",
        "We can use the `pandas` library to perform this transformation automatically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataframe to demonstrate\n",
        "data = {'sex': ['female', 'male', 'female', 'male', 'female']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform one-hot encoding on the 'sex' feature of df\n",
        "df_encoded = pd.get_dummies(df, columns=['sex'])\n",
        "\n",
        "# Display the result\n",
        "print(df_encoded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. TEXT PRE-PROCESSING AND VECTORIZATION</span><br>\n",
        "\n",
        "Before converting text to numbers, we often clean or \"pre-process\" the data to standardize it.\n",
        "\n",
        "### Common Pre-processing Steps\n",
        "\n",
        "1.  **Converting to lowercase:**\n",
        "    *   Example: `Reduction` $\\rightarrow$ `reduction`\n",
        "2.  **Converting to base-form (Stemming/Lemmatization):**\n",
        "    *   Example: `reduction` $\\rightarrow$ `reduce`\n",
        "\n",
        "### Vectorization\n",
        "Vectorization is the process of converting text into a numerical format (vectors). A common method is counting word occurrences or using TF-IDF.\n",
        "\n",
        "**Conceptual Vectorization Matrix:**\n",
        "\n",
        "| 0 | 1 | 2 | ... | n | class |\n",
        "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
        "| 0.03 | 0.71 | 0.00 | ... | 0.22 | positive |\n",
        "| 0.45 | 0.00 | 0.03 | ... | 0.19 | negative |\n",
        "| 0.14 | 0.18 | 0.00 | ... | 0.45 | positive |\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. BASIC FEATURE CONCEPTS (POS & NER)</span><br>\n",
        "\n",
        "Apart from raw vectorization, we can extract linguistic features from the text.\n",
        "\n",
        "### Basic Features List\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average length of words\n",
        "*   Special tweet features (hashtags, mentions)\n",
        "\n",
        "### Part-of-Speech (POS) Tagging\n",
        "POS tagging assigns a grammatical category to each word.\n",
        "\n",
        "| Word | POS |\n",
        "| :--- | :--- |\n",
        "| I | Pronoun |\n",
        "| have | Verb |\n",
        "| a | Article |\n",
        "| dog | Noun |\n",
        "\n",
        "### Named Entity Recognition (NER)\n",
        "NER identifies proper nouns and classifies them into categories like Person, Organization, or Country.\n",
        "\n",
        "| Noun | NER |\n",
        "| :--- | :--- |\n",
        "| Brian | Person |\n",
        "| DataCamp | Organization |\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. IMPLEMENTING BASIC FEATURE EXTRACTION</span><br>\n",
        "\n",
        "In this section, we will write Python code to extract basic features from text strings.\n",
        "\n",
        "### 5.1 Number of Characters\n",
        "We can calculate the length of a string including spaces and punctuation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the number of characters\n",
        "text = \"I don't know.\"\n",
        "num_char = len(text)\n",
        "\n",
        "# Print the number of characters\n",
        "print(f\"Text: {text}\")\n",
        "print(f\"Character Count: {num_char}\")\n",
        "\n",
        "# --- Applying to a DataFrame ---\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'review': [\"I don't know.\", \"I love Python.\", \"Data science is fun.\"]})\n",
        "\n",
        "# Create a 'num_chars' feature\n",
        "df['num_chars'] = df['review'].apply(len)\n",
        "print(\"\\nDataFrame with Character Counts:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 5.2 Number of Words\n",
        "To count words, we typically split the string by whitespace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the string into words\n",
        "text = \"Mary had a little lamb.\"\n",
        "words = text.split()\n",
        "\n",
        "# Print the list containing words\n",
        "print(f\"Words list: {words}\")\n",
        "\n",
        "# Print number of words\n",
        "print(f\"Word count: {len(words)}\")\n",
        "\n",
        "# --- Function Implementation ---\n",
        "def word_count(string):\n",
        "    # Split the string into words\n",
        "    words = string.split()\n",
        "    # Return length of words list\n",
        "    return len(words)\n",
        "\n",
        "# Create num_words feature in df\n",
        "df['num_words'] = df['review'].apply(word_count)\n",
        "print(\"\\nDataFrame with Word Counts:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 5.3 Average Word Length\n",
        "This feature can indicate the complexity of the vocabulary used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function that returns average word length\n",
        "def avg_word_length(x):\n",
        "    # Split the string into words\n",
        "    words = x.split()\n",
        "    \n",
        "    # Compute length of each word and store in a separate list\n",
        "    word_lengths = [len(word) for word in words]\n",
        "    \n",
        "    # Compute average word length\n",
        "    # Avoid division by zero if string is empty\n",
        "    if len(words) == 0:\n",
        "        return 0\n",
        "    \n",
        "    avg_word_length = sum(word_lengths) / len(words)\n",
        "    \n",
        "    # Return average word length\n",
        "    return avg_word_length\n",
        "\n",
        "# Create a new feature avg_word_length\n",
        "df['avg_word_length'] = df['review'].apply(avg_word_length)\n",
        "print(\"\\nDataFrame with Average Word Length:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. ADVANCED FEATURE EXTRACTION: HASHTAGS AND MENTIONS</span><br>\n",
        "\n",
        "For social media data (like Tweets), specific features like hashtags (`#`) and mentions (`@`) are very valuable.\n",
        "\n",
        "### Extracting Hashtags\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function that returns number of hashtags\n",
        "def hashtag_count(string):\n",
        "    # Split the string into words\n",
        "    words = string.split()\n",
        "    \n",
        "    # Create a list of hashtags\n",
        "    hashtags = [word for word in words if word.startswith('#')]\n",
        "    \n",
        "    # Return number of hashtags\n",
        "    return len(hashtags)\n",
        "\n",
        "# Test the function\n",
        "tweet = \"@janedoe This is my first tweet! #FirstTweet #Happy\"\n",
        "count = hashtag_count(tweet)\n",
        "\n",
        "print(f\"Tweet: {tweet}\")\n",
        "print(f\"Hashtag Count: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Other Potential Features\n",
        "Beyond hashtags, you can extract:\n",
        "*   **Number of sentences**\n",
        "*   **Number of paragraphs**\n",
        "*   **Words starting with an uppercase**\n",
        "*   **All-capital words**\n",
        "*   **Numeric quantities**\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. READABILITY TESTS</span><br>\n",
        "\n",
        "Readability tests determine how difficult an English passage is to understand. They often output a score corresponding to a grade level (e.g., primary school vs. college graduate).\n",
        "\n",
        "### Overview\n",
        "*   **Goal:** Determine readability of an English passage.\n",
        "*   **Scale:** Ranges from primary school to college graduate level.\n",
        "*   **Mechanism:** Mathematical formulas utilizing word count, syllable count, and sentence count.\n",
        "*   **Applications:** Fake news detection, opinion spam detection.\n",
        "\n",
        "### Common Readability Tests\n",
        "1.  **Flesch reading ease**\n",
        "2.  **Gunning fog index**\n",
        "3.  **Simple Measure of Gobbledygook (SMOG)**\n",
        "4.  **Dale-Chall score**\n",
        "\n",
        "### 7.1 Flesch Reading Ease\n",
        "One of the oldest and most widely used tests. It depends on two factors:\n",
        "1.  **Average Sentence Length:** Greater length $\\rightarrow$ Harder to read.\n",
        "2.  **Average Syllables per Word:** More syllables $\\rightarrow$ Harder to read.\n",
        "\n",
        "**Interpretation:** Higher score = Greater readability (Easier).\n",
        "\n",
        "| Reading ease score | Grade Level |\n",
        "| :--- | :--- |\n",
        "| 90-100 | 5 |\n",
        "| 80-90 | 6 |\n",
        "| 70-80 | 7 |\n",
        "| 60-70 | 8-9 |\n",
        "| 50-60 | 10-12 |\n",
        "| 30-50 | College |\n",
        "| 0-30 | College Graduate |\n",
        "\n",
        "### 7.2 Gunning Fog Index\n",
        "Developed in 1954. It also depends on average sentence length but focuses on \"complex words\" (words with 3+ syllables).\n",
        "\n",
        "**Interpretation:** Higher index = Lesser readability (Harder).\n",
        "\n",
        "| Fog index | Grade level | Fog index | Grade level |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| 17 | College graduate | 10 | High school sophomore |\n",
        "| 16 | College senior | 9 | High school freshman |\n",
        "| 15 | College junior | 8 | Eighth grade |\n",
        "| 14 | College sophomore | 7 | Seventh grade |\n",
        "| 13 | College freshman | 6 | Sixth grade |\n",
        "| 12 | High school senior | | |\n",
        "| 11 | High school junior | | |\n",
        "\n",
        "### 7.3 Implementation with `textatistic`\n",
        "The `textatistic` library allows for easy calculation of these scores.\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> You may need to install the library first using <code>!pip install textatistic</code>. </div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This code requires the textatistic library.\n",
        "# If not installed, uncomment the line below:\n",
        "# !pip install textatistic\n",
        "\n",
        "try:\n",
        "    # Import the Textatistic class\n",
        "    from textatistic import Textatistic\n",
        "\n",
        "    # Sample text\n",
        "    text = \"The quick brown fox jumps over the lazy dog. This is a simple sentence.\"\n",
        "\n",
        "    # Create a Textatistic Object\n",
        "    readability_scores = Textatistic(text).scores\n",
        "\n",
        "    # Generate scores\n",
        "    print(f\"Flesch Score: {readability_scores['flesch_score']}\")\n",
        "    print(f\"Gunning Fog Score: {readability_scores['gunningfog_score']}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"The 'textatistic' library is not installed. Please install it to run this block.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 8. CONCLUSION</span><br>\n",
        "\n",
        "In this notebook, we explored the fundamentals of Feature Engineering for NLP in Python.\n",
        "\n",
        "**Key Takeaways:**\n",
        "1.  **Data Types:** We distinguished between structured numerical data (like Iris) and unstructured textual data (like Movie Reviews).\n",
        "2.  **Encoding:** We learned how to use One-Hot Encoding to convert categorical variables into numerical features using `pd.get_dummies`.\n",
        "3.  **Basic Features:** We implemented Python functions to extract simple but powerful features such as character counts, word counts, and average word length.\n",
        "4.  **Social Media Features:** We saw how to parse specific tokens like hashtags from tweets.\n",
        "5.  **Readability:** We examined advanced linguistic features like the Flesch Reading Ease and Gunning Fog Index to quantify the complexity of a text.\n",
        "\n",
        "**Next Steps:**\n",
        "*   Apply these feature extraction techniques to a real-world dataset.\n",
        "*   Explore more advanced vectorization techniques like TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "*   Feed these extracted features into machine learning classifiers (like Logistic Regression or Naive Bayes) to perform sentiment analysis or text classification.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}