{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>Introduction to Audio Data in Python</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Spoken Language Processing in Python)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Dealing with Audio Files in Python](#section-1)\n",
        "2. [Frequency Examples & Importing Wave](#section-2)\n",
        "3. [Opening an Audio File](#section-3)\n",
        "4. [Converting Sound Wave Bytes to Integers](#section-4)\n",
        "5. [Finding the Frame Rate](#section-5)\n",
        "6. [Finding Sound Wave Timestamps](#section-6)\n",
        "7. [Visualizing Sound Waves](#section-7)\n",
        "8. [Conclusion](#conclusion)\n",
        "\n",
        "***\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip: Setup Required</b> <br>To make this notebook fully executable, we will first generate dummy audio files (`good-morning.wav` and `good-afternoon.wav`) in the code block below. In a real-world scenario, you would load your own existing .wav files.</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PREREQUISITE: GENERATING DUMMY DATA FOR THIS NOTEBOOK\n",
        "# Run this cell first to create the audio files used in the examples.\n",
        "\n",
        "import wave\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "def create_dummy_wav(filename, freq=440, duration=2, framerate=48000):\n",
        "    # Generate a sine wave\n",
        "    t = np.linspace(0, duration, int(framerate * duration))\n",
        "    amplitude = 10000 # Amplitude of the wave\n",
        "    audio_data = (np.sin(2 * np.pi * freq * t) * amplitude).astype(np.int16)\n",
        "    \n",
        "    with wave.open(filename, \"w\") as f:\n",
        "        f.setnchannels(1)      # Mono\n",
        "        f.setsampwidth(2)      # 2 bytes (16-bit)\n",
        "        f.setframerate(framerate)\n",
        "        f.writeframes(audio_data.tobytes())\n",
        "    print(f\"Created {filename}\")\n",
        "\n",
        "# Create the files expected by the tutorial\n",
        "create_dummy_wav(\"good-morning.wav\", freq=440) # A4 Note\n",
        "create_dummy_wav(\"good-afternoon.wav\", freq=880) # A5 Note\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. Dealing with Audio Files in Python</span><br>\n",
        "\n",
        "When working with spoken language processing in Python, the first step is understanding the nature of the data. Audio files come in various formats, and digital sound is measured in specific ways that determine the quality and size of the data.\n",
        "\n",
        "### Common Audio File Formats\n",
        "There are several different kinds of audio files you might encounter:\n",
        "\n",
        "| Extension | Description |\n",
        "| :--- | :--- |\n",
        "| **.mp3** | Compressed audio format, very common for music. |\n",
        "| **.wav** | Uncompressed audio format, high quality, standard for processing. |\n",
        "| **.m4a** | MPEG-4 Audio, often used by Apple devices. |\n",
        "| **.flac** | Free Lossless Audio Codec, high quality compressed format. |\n",
        "\n",
        "### Understanding Frequency\n",
        "Digital sounds are measured in **frequency**, typically expressed in **kHz** (kilohertz).\n",
        "\n",
        "*   **1 kHz** = 1,000 pieces of information per second.\n",
        "*   Higher frequency generally means higher audio quality but results in larger file sizes.\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. Frequency Examples & Importing Wave</span><br>\n",
        "\n",
        "Different types of audio require different frequencies depending on the complexity of the sound.\n",
        "\n",
        "### Typical Frequency Ranges\n",
        "\n",
        "| Audio Type | Frequency (Sample Rate) |\n",
        "| :--- | :--- |\n",
        "| **Streaming Songs** | ~32 kHz (or 44.1 kHz standard) |\n",
        "| **Audiobooks / Spoken Language** | Between 8 and 16 kHz |\n",
        "\n",
        "Since we cannot \"see\" audio files directly like we do with images or text, we must transform them into a numerical format that Python can process. The standard library for this in Python is `wave`.\n",
        "\n",
        "### Importing the Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard Python library for working with wav files\n",
        "import wave\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. Opening an Audio File</span><br>\n",
        "\n",
        "In this section, we will open an audio file named `good-morning.wav`. We treat audio files similarly to text files, opening them in read mode (`\"r\"`).\n",
        "\n",
        "### The Process\n",
        "1.  Import the audio file as a `wave` object.\n",
        "2.  Read the frames from the object.\n",
        "3.  The output is initially in **bytes**, which is not immediately human-readable.\n",
        "\n",
        "#### Original Code Concept\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import audio file as wave object\n",
        "good_morning = wave.open(\"good-morning.wav\", \"r\")\n",
        "\n",
        "# Convert wave object to bytes\n",
        "# readframes(-1) reads all frames in the file\n",
        "good_morning_soundwave = good_morning.readframes(-1)\n",
        "\n",
        "# View the wav file in byte form\n",
        "print(good_morning_soundwave[:20]) # Printing first 20 bytes to avoid clutter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Enhanced Executable Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wave\n",
        "\n",
        "# 1. Open the wave file\n",
        "# We use the file we generated in the Setup step\n",
        "good_morning = wave.open(\"good-morning.wav\", \"r\")\n",
        "\n",
        "# 2. Read all frames as bytes\n",
        "good_morning_soundwave = good_morning.readframes(-1)\n",
        "\n",
        "# 3. Inspect the raw byte data\n",
        "print(f\"Type of data: {type(good_morning_soundwave)}\")\n",
        "print(f\"First 50 bytes: {good_morning_soundwave[:50]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Working with audio is different from other data types. A very small sample of audio (even a few seconds) contains a large amount of information. The raw byte output (e.g., `b'\\xfd\\xff...`) must be converted to be useful. </div>\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Converting Sound Wave Bytes to Integers</span><br>\n",
        "\n",
        "Raw bytes are difficult to manipulate mathematically. To perform analysis or visualization, we must convert these bytes into integers. We use the **NumPy** library for this efficient conversion.\n",
        "\n",
        "### Conversion Steps\n",
        "1.  Import `numpy`.\n",
        "2.  Use `np.frombuffer()` to convert the byte string into a NumPy array.\n",
        "3.  Specify the data type (`dtype`). For standard `.wav` files, this is often `int16` (16-bit integers).\n",
        "\n",
        "#### Code Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert soundwave_gm from bytes to integers\n",
        "# We use 'int16' because standard wav audio is often 16-bit depth\n",
        "signal_gm = np.frombuffer(good_morning_soundwave, dtype='int16')\n",
        "\n",
        "# Show the first 10 items\n",
        "print(\"First 10 integer values of the signal:\")\n",
        "print(signal_gm[:10])\n",
        "\n",
        "# Check the shape to see how many data points we have\n",
        "print(f\"\\nTotal data points: {len(signal_gm)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. Finding the Frame Rate</span><br>\n",
        "\n",
        "The **Frame Rate** (or Sample Rate) tells us how many data points exist per second of audio. This is crucial for calculating the duration of the audio file.\n",
        "\n",
        "### Key Formulas\n",
        "1.  **Frequency (Hz)** = `wave_object.getframerate()`\n",
        "2.  **Duration (Seconds)** = $\\frac{\\text{Length of wave object array}}{\\text{Frequency (Hz)}}$\n",
        "\n",
        "#### Code Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the frame rate from the wave object\n",
        "framerate_gm = good_morning.getframerate()\n",
        "\n",
        "# Show the frame rate\n",
        "print(f\"Frame Rate: {framerate_gm} Hz\")\n",
        "\n",
        "# Calculate duration\n",
        "# We use the length of the numpy array (signal_gm) divided by the framerate\n",
        "duration = len(signal_gm) / framerate_gm\n",
        "print(f\"Duration: {duration} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. Finding Sound Wave Timestamps</span><br>\n",
        "\n",
        "To visualize audio, we need an X-axis representing **Time**. Since we only have the signal amplitude (Y-axis), we must generate the timestamps mathematically.\n",
        "\n",
        "We use `np.linspace()` to generate evenly spaced values.\n",
        "\n",
        "### Understanding `np.linspace`\n",
        "`np.linspace(start, stop, num)` returns `num` evenly spaced samples, calculated over the interval `[start, stop]`.\n",
        "\n",
        "#### Code Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of linspace logic\n",
        "print(\"Linspace Example (1 to 10):\")\n",
        "print(np.linspace(start=1, stop=10, num=10))\n",
        "\n",
        "# Get the timestamps of the good morning sound wave\n",
        "# Start: 0 seconds\n",
        "# Stop: Duration of the file (len(signal) / framerate)\n",
        "# Num: Total number of data points (len(signal))\n",
        "\n",
        "time_gm = np.linspace(start=0,\n",
        "                      stop=len(signal_gm) / framerate_gm,\n",
        "                      num=len(signal_gm))\n",
        "\n",
        "# View first 10 timestamps\n",
        "print(\"\\nFirst 10 timestamps (seconds):\")\n",
        "print(time_gm[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. Visualizing Sound Waves</span><br>\n",
        "\n",
        "Visualizing audio data allows us to compare different sound waves. In this example, we will compare \"Good Morning\" with \"Good Afternoon\".\n",
        "\n",
        "### Preparation\n",
        "We need to process the second file (`good-afternoon.wav`) exactly the same way we processed the first one.\n",
        "\n",
        "#### Step 1: Process the Second File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open the second file\n",
        "good_afternoon = wave.open(\"good-afternoon.wav\", \"r\")\n",
        "\n",
        "# Read frames and convert to integers\n",
        "soundwave_ga = good_afternoon.readframes(-1)\n",
        "signal_ga = np.frombuffer(soundwave_ga, dtype='int16')\n",
        "\n",
        "# Get framerate\n",
        "framerate_ga = good_afternoon.getframerate()\n",
        "\n",
        "# Create timestamps\n",
        "time_ga = np.linspace(start=0,\n",
        "                      stop=len(signal_ga) / framerate_ga,\n",
        "                      num=len(signal_ga))\n",
        "\n",
        "print(f\"Processed Good Afternoon: {len(signal_ga)} samples at {framerate_ga} Hz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Step 2: Plotting with Matplotlib\n",
        "We use `matplotlib.pyplot` to create the visualization. We will plot Time (x-axis) vs Amplitude (y-axis).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize figure and setup title\n",
        "plt.figure(figsize=(10, 6)) # Added figsize for better visibility in notebook\n",
        "plt.title(\"Good Afternoon vs. Good Morning\")\n",
        "\n",
        "# x and y axis labels\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "\n",
        "# Add good morning and good afternoon values\n",
        "# We use alpha=0.5 to make the plots semi-transparent so we can see overlap\n",
        "plt.plot(time_ga, signal_ga, label=\"Good Afternoon\")\n",
        "plt.plot(time_gm, signal_gm, label=\"Good Morning\", alpha=0.5)\n",
        "\n",
        "# Create a legend and show our plot\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 8. Conclusion</span><br>\n",
        "\n",
        "In this notebook, we explored the fundamentals of processing audio data in Python. We covered the entire pipeline from raw file to visualization:\n",
        "\n",
        "1.  **Understanding Formats:** We learned about `.wav` files and frequency (kHz).\n",
        "2.  **Loading Data:** We used the `wave` library to read raw bytes.\n",
        "3.  **Data Conversion:** We used `numpy` to convert raw bytes into usable integers (`int16`).\n",
        "4.  **Time Domain:** We calculated the duration and generated timestamps using `np.linspace`.\n",
        "5.  **Visualization:** We used `matplotlib` to plot the sound waves, allowing for visual comparison of audio signals.\n",
        "\n",
        "**Next Steps:**\n",
        "*   Try applying Fast Fourier Transforms (FFT) to analyze the frequency content.\n",
        "*   Explore the `librosa` library, which abstracts many of these steps for easier audio processing.\n",
        "*   Use these techniques to prepare audio data for machine learning models (e.g., speech recognition).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}